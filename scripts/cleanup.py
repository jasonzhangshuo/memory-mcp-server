#!/usr/bin/env python3
"""æ¸…ç†è„šæœ¬ï¼šæ¸…ç†æ— ç”¨çš„ JSON æ–‡ä»¶å’Œè¿‡æœŸçš„ FTS5 ç´¢å¼•æ•°æ®

ä½¿ç”¨æ–¹æ³•:
    python scripts/cleanup.py [--dry-run]

å‚æ•°:
    --dry-run: è¯•è¿è¡Œæ¨¡å¼ï¼Œåªæ˜¾ç¤ºè¦åˆ é™¤çš„å†…å®¹ï¼Œä¸å®é™…åˆ é™¤
"""

import os
import sys
import asyncio
import aiosqlite
import argparse
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from storage.db import DB_PATH

ENTRIES_DIR = os.path.join(project_root, "entries")


async def cleanup_orphaned_json_files(dry_run: bool = False) -> dict:
    """æ¸…ç†æ— ç”¨çš„ JSON æ–‡ä»¶ï¼ˆæ•°æ®åº“ä¸­æ²¡æœ‰å¼•ç”¨çš„ï¼‰"""
    
    # è·å–æ•°æ®åº“ä¸­æ‰€æœ‰æœ‰æ•ˆçš„è®°å¿† ID
    async with aiosqlite.connect(DB_PATH) as db:
        cursor = await db.execute("SELECT id FROM memories")
        rows = await cursor.fetchall()
        valid_ids = {row[0] for row in rows}
    
    print(f"ğŸ’¾ æ•°æ®åº“ä¸­æœ‰æ•ˆè®°å¿†: {len(valid_ids)} æ¡")
    
    # æ‰«æ entries ç›®å½•ä¸‹çš„æ‰€æœ‰ JSON æ–‡ä»¶
    total_files = 0
    orphaned_files = []
    kept_files = 0
    total_size = 0
    
    for root, dirs, files in os.walk(ENTRIES_DIR):
        for file in files:
            if file.endswith('.json'):
                total_files += 1
                file_id = file.replace('.json', '')
                file_path = os.path.join(root, file)
                
                if file_id not in valid_ids:
                    # æ— ç”¨æ–‡ä»¶
                    file_size = os.path.getsize(file_path)
                    total_size += file_size
                    orphaned_files.append((file_path, file_size))
                else:
                    kept_files += 1
    
    print(f"\nğŸ“ æ‰«æç»“æœ:")
    print(f"   æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"   ä¿ç•™: {kept_files} ä¸ª")
    print(f"   æ— ç”¨: {len(orphaned_files)} ä¸ª ({total_size / 1024:.1f} KB)")
    
    # åˆ é™¤æ— ç”¨æ–‡ä»¶
    deleted_count = 0
    if orphaned_files:
        if dry_run:
            print(f"\nâš ï¸  è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…åˆ é™¤")
            if len(orphaned_files) <= 10:
                print(f"\næ— ç”¨æ–‡ä»¶åˆ—è¡¨:")
                for path, size in orphaned_files:
                    print(f"  - {path} ({size} bytes)")
            else:
                print(f"\nå‰10ä¸ªæ— ç”¨æ–‡ä»¶:")
                for path, size in orphaned_files[:10]:
                    print(f"  - {path} ({size} bytes)")
                print(f"  ... è¿˜æœ‰ {len(orphaned_files) - 10} ä¸ªæ–‡ä»¶")
        else:
            print(f"\nğŸ—‘ï¸  å¼€å§‹åˆ é™¤æ— ç”¨æ–‡ä»¶...")
            for file_path, _ in orphaned_files:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                    if deleted_count % 100 == 0:
                        print(f"   å·²åˆ é™¤ {deleted_count}/{len(orphaned_files)}...")
                except Exception as e:
                    print(f"   åˆ é™¤å¤±è´¥: {file_path} - {e}")
            
            print(f"âœ… åˆ é™¤å®Œæˆ: {deleted_count} ä¸ªæ–‡ä»¶")
    
    return {
        "total_files": total_files,
        "kept_files": kept_files,
        "orphaned_files": len(orphaned_files),
        "deleted_files": deleted_count,
        "freed_space_kb": total_size / 1024
    }


async def cleanup_fts5_index(dry_run: bool = False) -> dict:
    """æ¸…ç† FTS5 ç´¢å¼•ä¸­çš„è¿‡æœŸæ•°æ®ï¼ˆä¸»è¡¨ä¸­å·²åˆ é™¤çš„è®°å½•ï¼‰"""
    
    async with aiosqlite.connect(DB_PATH) as db:
        # è·å–ä¸»è¡¨ä¸­çš„æ‰€æœ‰ ID
        cursor = await db.execute("SELECT id FROM memories")
        rows = await cursor.fetchall()
        valid_ids = {row[0] for row in rows}
        
        # è·å– FTS5 è¡¨ä¸­çš„æ‰€æœ‰ ID
        cursor = await db.execute("SELECT id FROM memories_fts")
        rows = await cursor.fetchall()
        fts_ids = {row[0] for row in rows}
        
        # æ‰¾å‡º FTS5 ä¸­çš„è¿‡æœŸè®°å½•
        orphaned_ids = fts_ids - valid_ids
        
        print(f"\nğŸ” FTS5 ç´¢å¼•æ£€æŸ¥:")
        print(f"   ä¸»è¡¨è®°å½•: {len(valid_ids)} æ¡")
        print(f"   FTS5 è®°å½•: {len(fts_ids)} æ¡")
        print(f"   è¿‡æœŸè®°å½•: {len(orphaned_ids)} æ¡")
        
        deleted_count = 0
        if orphaned_ids:
            if dry_run:
                print(f"\nâš ï¸  è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…åˆ é™¤")
                if len(orphaned_ids) <= 10:
                    print(f"\nè¿‡æœŸè®°å½• ID:")
                    for id in list(orphaned_ids)[:10]:
                        print(f"  - {id}")
                else:
                    print(f"\nå‰10ä¸ªè¿‡æœŸè®°å½• ID:")
                    for id in list(orphaned_ids)[:10]:
                        print(f"  - {id}")
                    print(f"  ... è¿˜æœ‰ {len(orphaned_ids) - 10} æ¡")
            else:
                print(f"\nğŸ—‘ï¸  å¼€å§‹æ¸…ç† FTS5 è¿‡æœŸè®°å½•...")
                # åˆ é™¤ FTS5 ä¸­çš„è¿‡æœŸè®°å½•
                for id in orphaned_ids:
                    try:
                        await db.execute("DELETE FROM memories_fts WHERE id = ?", (id,))
                        deleted_count += 1
                        if deleted_count % 100 == 0:
                            print(f"   å·²åˆ é™¤ {deleted_count}/{len(orphaned_ids)}...")
                    except Exception as e:
                        print(f"   åˆ é™¤å¤±è´¥: {id} - {e}")
                
                await db.commit()
                print(f"âœ… æ¸…ç†å®Œæˆ: {deleted_count} æ¡è®°å½•")
        elif len(fts_ids) == len(valid_ids):
            print(f"âœ… FTS5 ç´¢å¼•çŠ¶æ€æ­£å¸¸ï¼Œæ— éœ€æ¸…ç†")
        
        return {
            "main_table_records": len(valid_ids),
            "fts_records": len(fts_ids),
            "orphaned_records": len(orphaned_ids),
            "deleted_records": deleted_count
        }


async def cleanup_empty_directories(dry_run: bool = False) -> dict:
    """æ¸…ç†ç©ºç›®å½•"""
    
    deleted_dirs = []
    
    # ä»æœ€æ·±å±‚å¼€å§‹éå†ï¼Œç¡®ä¿å­ç›®å½•å…ˆè¢«åˆ é™¤
    for root, dirs, files in os.walk(ENTRIES_DIR, topdown=False):
        if root == ENTRIES_DIR:
            continue
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©ºï¼ˆå¿½ç•¥ .DS_Storeï¼‰
        contents = os.listdir(root)
        real_contents = [f for f in contents if f != '.DS_Store']
        
        if not real_contents:
            deleted_dirs.append(root)
            if not dry_run:
                try:
                    # åˆ é™¤ .DS_Storeï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    for f in contents:
                        os.remove(os.path.join(root, f))
                    os.rmdir(root)
                except Exception as e:
                    print(f"   åˆ é™¤ç›®å½•å¤±è´¥: {root} - {e}")
    
    if deleted_dirs:
        print(f"\nğŸ“‚ ç©ºç›®å½•æ¸…ç†:")
        if dry_run:
            print(f"   æ‰¾åˆ° {len(deleted_dirs)} ä¸ªç©ºç›®å½•ï¼ˆè¯•è¿è¡Œæ¨¡å¼ï¼‰")
            if len(deleted_dirs) <= 10:
                for d in deleted_dirs:
                    print(f"   - {d}")
            else:
                for d in deleted_dirs[:10]:
                    print(f"   - {d}")
                print(f"   ... è¿˜æœ‰ {len(deleted_dirs) - 10} ä¸ªç›®å½•")
        else:
            print(f"   å·²åˆ é™¤ {len(deleted_dirs)} ä¸ªç©ºç›®å½•")
    else:
        print(f"\nğŸ“‚ æ²¡æœ‰ç©ºç›®å½•éœ€è¦æ¸…ç†")
    
    return {
        "empty_directories": len(deleted_dirs),
        "deleted_directories": 0 if dry_run else len(deleted_dirs)
    }


async def main():
    parser = argparse.ArgumentParser(description='æ¸…ç†æ— ç”¨çš„è®°å¿†æ–‡ä»¶å’Œç´¢å¼•æ•°æ®')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…åˆ é™¤')
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ§¹ ä¸ªäººè®°å¿†ç³»ç»Ÿæ¸…ç†å·¥å…·")
    print("=" * 60)
    
    if args.dry_run:
        print("\nâš ï¸  è¿è¡Œæ¨¡å¼: è¯•è¿è¡Œï¼ˆä¸ä¼šå®é™…åˆ é™¤ä»»ä½•å†…å®¹ï¼‰\n")
    else:
        print("\nâš ï¸  è¿è¡Œæ¨¡å¼: å®é™…æ¸…ç†ï¼ˆå°†åˆ é™¤æ— ç”¨æ–‡ä»¶ï¼‰\n")
    
    # 1. æ¸…ç†æ— ç”¨çš„ JSON æ–‡ä»¶
    print("\n" + "=" * 60)
    print("1ï¸âƒ£  æ¸…ç†æ— ç”¨çš„ JSON æ–‡ä»¶")
    print("=" * 60)
    json_result = await cleanup_orphaned_json_files(dry_run=args.dry_run)
    
    # 2. æ¸…ç† FTS5 ç´¢å¼•
    print("\n" + "=" * 60)
    print("2ï¸âƒ£  æ¸…ç† FTS5 ç´¢å¼•è¿‡æœŸæ•°æ®")
    print("=" * 60)
    fts_result = await cleanup_fts5_index(dry_run=args.dry_run)
    
    # 3. æ¸…ç†ç©ºç›®å½•
    print("\n" + "=" * 60)
    print("3ï¸âƒ£  æ¸…ç†ç©ºç›®å½•")
    print("=" * 60)
    dir_result = await cleanup_empty_directories(dry_run=args.dry_run)
    
    # æ±‡æ€»æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¸…ç†æ±‡æ€»")
    print("=" * 60)
    
    if args.dry_run:
        print(f"\nå°†è¦æ¸…ç†:")
        print(f"  - JSON æ–‡ä»¶: {json_result['orphaned_files']} ä¸ª ({json_result['freed_space_kb']:.1f} KB)")
        print(f"  - FTS5 è®°å½•: {fts_result['orphaned_records']} æ¡")
        print(f"  - ç©ºç›®å½•: {dir_result['empty_directories']} ä¸ª")
        print(f"\næç¤º: è¿è¡Œ 'python scripts/cleanup.py' æ‰§è¡Œå®é™…æ¸…ç†")
    else:
        print(f"\nå·²æ¸…ç†:")
        print(f"  - JSON æ–‡ä»¶: {json_result['deleted_files']} ä¸ª ({json_result['freed_space_kb']:.1f} KB)")
        print(f"  - FTS5 è®°å½•: {fts_result['deleted_records']} æ¡")
        print(f"  - ç©ºç›®å½•: {dir_result['deleted_directories']} ä¸ª")
        print(f"\nâœ… æ¸…ç†å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
