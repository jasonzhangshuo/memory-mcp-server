# ç³»ç»Ÿç»´æŠ¤æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ç»´æŠ¤ä¸ªäººè®°å¿†ç³»ç»Ÿï¼Œä¿æŒå…¶å¥åº·è¿è¡Œã€‚

## ğŸ“‹ ç›®å½•

1. [æ¸…ç†å·¥å…·](#æ¸…ç†å·¥å…·)
2. [æµ‹è¯•éš”ç¦»](#æµ‹è¯•éš”ç¦»)
3. [å®šæœŸç»´æŠ¤](#å®šæœŸç»´æŠ¤)
4. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
5. [å¤‡ä»½ç­–ç•¥](#å¤‡ä»½ç­–ç•¥)

---

## ğŸ§¹ æ¸…ç†å·¥å…·

### ä¸ºä»€ä¹ˆéœ€è¦æ¸…ç†ï¼Ÿ

åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ï¼Œç³»ç»Ÿä¼šäº§ç”Ÿæ— ç”¨æ–‡ä»¶ï¼š

1. **åˆ é™¤è®°å¿†å**ï¼šJSON æ–‡ä»¶ä¸ä¼šè‡ªåŠ¨åˆ é™¤
2. **æµ‹è¯•æœŸé—´**ï¼šæµ‹è¯•è„šæœ¬å¯èƒ½åˆ›å»ºå¤§é‡æ•°æ®
3. **ç´¢å¼•ä¸åŒæ­¥**ï¼šFTS5 ç´¢å¼•å¯èƒ½åŒ…å«å·²åˆ é™¤è®°å¿†çš„å¼•ç”¨

### ä½¿ç”¨æ¸…ç†è„šæœ¬

```bash
# æŸ¥çœ‹å°†è¦æ¸…ç†çš„å†…å®¹ï¼ˆæ¨èï¼‰
python scripts/cleanup.py --dry-run

# æ‰§è¡Œæ¸…ç†
python scripts/cleanup.py
```

### æ¸…ç†å†…å®¹

| æ¸…ç†é¡¹ | è¯´æ˜ | é£é™© |
|-------|------|------|
| æ— ç”¨ JSON æ–‡ä»¶ | æ•°æ®åº“æœªå¼•ç”¨çš„æ–‡ä»¶ | âœ… å®‰å…¨ |
| FTS5 è¿‡æœŸè®°å½• | ç´¢å¼•ä¸­çš„è¿‡æœŸæ•°æ® | âœ… å®‰å…¨ |
| ç©ºç›®å½• | entries ä¸‹çš„ç©ºç›®å½• | âœ… å®‰å…¨ |

**æ³¨æ„**ï¼šæ¸…ç†è„šæœ¬åªåˆ é™¤ç¡®è®¤æ— ç”¨çš„æ•°æ®ï¼Œä¸ä¼šå½±å“æœ‰æ•ˆè®°å¿†ã€‚

---

## ğŸ§ª æµ‹è¯•éš”ç¦»

### ä¸ºä»€ä¹ˆéœ€è¦éš”ç¦»ï¼Ÿ

ç›´æ¥è¿è¡Œæµ‹è¯•è„šæœ¬ä¼šï¼š

- âŒ æ±¡æŸ“ç”Ÿäº§æ•°æ®åº“
- âŒ åˆ›å»ºå¤§é‡æµ‹è¯•è®°å¿†
- âŒ å½±å“ FTS5 ç´¢å¼•

### ä½¿ç”¨æµ‹è¯•è„šæœ¬

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆæ¨èï¼‰
./scripts/run_tests.sh

# è¿è¡Œç‰¹å®šæµ‹è¯•
./scripts/run_tests.sh regression   # å›å½’æµ‹è¯•
./scripts/run_tests.sh stability    # ç¨³å®šæ€§æµ‹è¯•
./scripts/run_tests.sh performance  # æ€§èƒ½æµ‹è¯•
```

### æµ‹è¯•éš”ç¦»æœºåˆ¶

æµ‹è¯•è„šæœ¬ä¼šè‡ªåŠ¨ï¼š

1. âœ… è®¾ç½® `TEST_MODE=true` ç¯å¢ƒå˜é‡
2. âœ… ä½¿ç”¨ç‹¬ç«‹çš„ `test_memory.db`
3. âœ… ä½¿ç”¨ç‹¬ç«‹çš„ `test_entries/` ç›®å½•
4. âœ… æµ‹è¯•å®Œæˆåæ¸…ç†æµ‹è¯•æ•°æ®

### æ‰‹åŠ¨æ§åˆ¶æµ‹è¯•æ¨¡å¼

å¦‚æœéœ€è¦è°ƒè¯•æµ‹è¯•ï¼š

```bash
# å¯ç”¨æµ‹è¯•æ¨¡å¼
export TEST_MODE=true

# è¿è¡Œæµ‹è¯•ï¼ˆä¸ä¼šè‡ªåŠ¨æ¸…ç†ï¼‰
python tests/test_regression.py

# æ£€æŸ¥æµ‹è¯•æ•°æ®
sqlite3 test_memory.db "SELECT COUNT(*) FROM memories"

# æ‰‹åŠ¨æ¸…ç†
rm -rf test_memory.db test_entries/
```

---

## ğŸ—“ï¸ å®šæœŸç»´æŠ¤

### ç»´æŠ¤æ¸…å•

å»ºè®®æ¯æœˆæ‰§è¡Œä¸€æ¬¡ï¼š

```bash
# 1. å¤‡ä»½æ•°æ®åº“
cp memory.db backups/memory_$(date +%Y%m%d).db

# 2. è¿è¡Œæ¸…ç†
python scripts/cleanup.py --dry-run  # å…ˆæ£€æŸ¥
python scripts/cleanup.py             # å†æ¸…ç†

# 3. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
python -c "
import asyncio
import aiosqlite

async def check():
    async with aiosqlite.connect('memory.db') as db:
        # ä¸»è¡¨è®°å½•æ•°
        cursor = await db.execute('SELECT COUNT(*) FROM memories')
        main_count = (await cursor.fetchone())[0]
        
        # FTS5 è®°å½•æ•°
        cursor = await db.execute('SELECT COUNT(*) FROM memories_fts')
        fts_count = (await cursor.fetchone())[0]
        
        # JSON æ–‡ä»¶æ•°
        import os
        json_count = sum(1 for root, dirs, files in os.walk('entries') 
                        for f in files if f.endswith('.json'))
        
        print(f'ä¸»è¡¨: {main_count}, FTS5: {fts_count}, JSON: {json_count}')
        
        if main_count == fts_count == json_count:
            print('âœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡')
        else:
            print('âš ï¸  æ•°æ®ä¸ä¸€è‡´ï¼Œå»ºè®®è¿è¡Œæ¸…ç†è„šæœ¬')

asyncio.run(check())
"

# 4. è¿è¡Œæµ‹è¯•ï¼ˆå¯é€‰ï¼‰
./scripts/run_tests.sh regression
```

### è‡ªåŠ¨åŒ–ç»´æŠ¤ï¼ˆå¯é€‰ï¼‰

ä½¿ç”¨ cron å®šæœŸæ¸…ç†ï¼š

```bash
# è®¾ç½®å®šæœŸä»»åŠ¡
./scripts/setup_cron.sh
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### æœç´¢è¿”å›ç»“æœä¸å®Œæ•´

**ç—‡çŠ¶**ï¼šæœç´¢åªè¿”å›éƒ¨åˆ†è®°å¿†ï¼Œä½†æ•°æ®åº“ä¸­ç¡®å®æœ‰æ›´å¤šè®°å½•ã€‚

**åŸå› **ï¼š
1. entry_path è·¯å¾„é”™è¯¯
2. JSON æ–‡ä»¶ä¸¢å¤±
3. FTS5 ç´¢å¼•ä¸åŒæ­¥

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
sqlite3 memory.db "
SELECT 
    (SELECT COUNT(*) FROM memories) as main_count,
    (SELECT COUNT(*) FROM memories_fts) as fts_count
"

# 2. æ£€æŸ¥ entry_path
sqlite3 memory.db "SELECT id, title, entry_path FROM memories LIMIT 5"

# 3. æ£€æŸ¥ JSON æ–‡ä»¶æ˜¯å¦å­˜åœ¨
python -c "
import sqlite3
import os

conn = sqlite3.connect('memory.db')
cursor = conn.execute('SELECT id, entry_path FROM memories')

missing = []
for row in cursor:
    if not os.path.exists(row[1]):
        missing.append((row[0], row[1]))

if missing:
    print(f'âŒ ç¼ºå¤± {len(missing)} ä¸ª JSON æ–‡ä»¶:')
    for id, path in missing[:10]:
        print(f'  - {id}: {path}')
else:
    print('âœ… æ‰€æœ‰ JSON æ–‡ä»¶éƒ½å­˜åœ¨')
"

# 4. å¦‚æœæ˜¯è·¯å¾„é—®é¢˜ï¼Œæ‰¹é‡ä¿®å¤
# ä¾‹å¦‚ï¼šå°† 'Jasonè®°å¿†' æ›¿æ¢ä¸º 'Jasonmemory'
sqlite3 memory.db "
UPDATE memories 
SET entry_path = REPLACE(entry_path, 'æ—§è·¯å¾„', 'æ–°è·¯å¾„');
SELECT changes();
"

# 5. é‡å»º FTS5 ç´¢å¼•
sqlite3 memory.db "
DELETE FROM memories_fts;
INSERT INTO memories_fts(id, title, content) 
SELECT id, title, content FROM memories;
"

# 6. è¿è¡Œæ¸…ç†è„šæœ¬
python scripts/cleanup.py
```

### æµ‹è¯•æ±¡æŸ“äº†ç”Ÿäº§æ•°æ®

**ç—‡çŠ¶**ï¼šç”Ÿäº§æ•°æ®åº“ä¸­å‡ºç°äº†å¤§é‡æµ‹è¯•æ•°æ®ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. ç«‹å³åœæ­¢æ‰€æœ‰æµ‹è¯•è¿›ç¨‹
ps aux | grep test | grep -v grep | awk '{print $2}' | xargs kill

# 2. è¯†åˆ«æµ‹è¯•æ•°æ®ï¼ˆé€šå¸¸æ ‡é¢˜åŒ…å«"æµ‹è¯•"ï¼‰
sqlite3 memory.db "SELECT COUNT(*) FROM memories WHERE title LIKE '%æµ‹è¯•%'"

# 3. åˆ é™¤æµ‹è¯•æ•°æ®
sqlite3 memory.db "
DELETE FROM memories WHERE title LIKE '%æµ‹è¯•%';
SELECT changes();
"

# 4. æ¸…ç†æ— ç”¨æ–‡ä»¶
python scripts/cleanup.py

# 5. é‡æ–°åŒæ­¥åˆ°é£ä¹¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
python -c "
import asyncio
from models import MemorySyncToFeishuInput
from tools.memory_sync_to_feishu import memory_sync_to_feishu

asyncio.run(memory_sync_to_feishu(MemorySyncToFeishuInput(dry_run=False)))
"
```

### é£ä¹¦åŒæ­¥å¤±è´¥

**ç—‡çŠ¶**ï¼šé£ä¹¦åŒæ­¥å¡ä½æˆ–å¤±è´¥ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. æ£€æŸ¥ token æ˜¯å¦æœ‰æ•ˆ
cat .user_token.json | python -m json.tool

# 2. æµ‹è¯•é£ä¹¦è¿æ¥
python -c "
import asyncio
from sync.feishu_client import FeishuClient

async def test():
    try:
        client = FeishuClient()
        token = await client.get_access_token()
        print(f'âœ… Token æœ‰æ•ˆ: {token[:20]}...')
        
        result = await client.list_records(page_size=1)
        print(f'âœ… è¯»å–æˆåŠŸ: {len(result.get(\"items\", []))} æ¡')
    except Exception as e:
        print(f'âŒ è¿æ¥å¤±è´¥: {e}')

asyncio.run(test())
"

# 3. å¦‚æœ token è¿‡æœŸï¼Œé‡æ–°æˆæƒ
# ï¼ˆéœ€è¦æ‰‹åŠ¨è®¿é—®é£ä¹¦æˆæƒé¡µé¢ï¼‰

# 4. ç¦ç”¨è‡ªåŠ¨åŒæ­¥ï¼ˆå¦‚æœé¢‘ç¹å¤±è´¥ï¼‰
# ä¿®æ”¹ memory_add å‡½æ•°ï¼Œæ³¨é‡Šæ‰ auto_sync è°ƒç”¨
```

---

## ğŸ’¾ å¤‡ä»½ç­–ç•¥

### è‡ªåŠ¨å¤‡ä»½è„šæœ¬

åˆ›å»º `scripts/backup.sh`ï¼š

```bash
#!/bin/bash
# æ¯æ—¥å¤‡ä»½è„šæœ¬

BACKUP_DIR="$HOME/backups/memory"
mkdir -p "$BACKUP_DIR"

# å¤‡ä»½æ•°æ®åº“
DATE=$(date +%Y%m%d_%H%M%S)
cp memory.db "$BACKUP_DIR/memory_$DATE.db"

# åªä¿ç•™æœ€è¿‘ 30 å¤©çš„å¤‡ä»½
find "$BACKUP_DIR" -name "memory_*.db" -mtime +30 -delete

echo "âœ… å¤‡ä»½å®Œæˆ: memory_$DATE.db"
```

### æ·»åŠ åˆ° crontab

```bash
# æ¯å¤©å‡Œæ™¨ 3 ç‚¹å¤‡ä»½
0 3 * * * cd /path/to/memory-mcp-server && bash scripts/backup.sh
```

### æ‰‹åŠ¨å¤‡ä»½

```bash
# å®Œæ•´å¤‡ä»½ï¼ˆæ•°æ®åº“ + æ¡ç›®ï¼‰
tar -czf memory_backup_$(date +%Y%m%d).tar.gz memory.db entries/

# ä»…å¤‡ä»½æ•°æ®åº“
cp memory.db memory_backup_$(date +%Y%m%d).db
```

### æ¢å¤å¤‡ä»½

```bash
# æ¢å¤æ•°æ®åº“
cp memory_backup_20260117.db memory.db

# æ¢å¤å®Œæ•´å¤‡ä»½
tar -xzf memory_backup_20260117.tar.gz
```

---

## ğŸ“Š å¥åº·æ£€æŸ¥è„šæœ¬

åˆ›å»º `scripts/health_check.py`ï¼š

```python
#!/usr/bin/env python3
"""ç³»ç»Ÿå¥åº·æ£€æŸ¥è„šæœ¬"""

import asyncio
import aiosqlite
import os
from pathlib import Path

async def health_check():
    print("=" * 60)
    print("ğŸ¥ ä¸ªäººè®°å¿†ç³»ç»Ÿå¥åº·æ£€æŸ¥")
    print("=" * 60)
    print()
    
    issues = []
    
    # 1. æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
    if not os.path.exists("memory.db"):
        issues.append("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
    else:
        print("âœ… æ•°æ®åº“æ–‡ä»¶å­˜åœ¨")
        
        # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
        async with aiosqlite.connect("memory.db") as db:
            cursor = await db.execute("SELECT COUNT(*) FROM memories")
            main_count = (await cursor.fetchone())[0]
            
            cursor = await db.execute("SELECT COUNT(*) FROM memories_fts")
            fts_count = (await cursor.fetchone())[0]
            
            print(f"   ä¸»è¡¨è®°å½•: {main_count}")
            print(f"   FTS5 è®°å½•: {fts_count}")
            
            if main_count != fts_count:
                issues.append(f"âš ï¸  ç´¢å¼•ä¸åŒæ­¥ï¼šä¸»è¡¨ {main_count}ï¼ŒFTS5 {fts_count}")
    
    # 2. æ£€æŸ¥ JSON æ–‡ä»¶
    if not os.path.exists("entries"):
        issues.append("âŒ æ¡ç›®ç›®å½•ä¸å­˜åœ¨")
    else:
        json_count = sum(1 for root, dirs, files in os.walk("entries")
                        for f in files if f.endswith(".json"))
        print(f"âœ… JSON æ–‡ä»¶: {json_count} ä¸ª")
        
        if main_count != json_count:
            issues.append(f"âš ï¸  æ–‡ä»¶æ•°ä¸åŒ¹é…ï¼šæ•°æ®åº“ {main_count}ï¼ŒJSON {json_count}")
    
    # 3. æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(".env"):
        issues.append("âš ï¸  .env é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
    else:
        print("âœ… .env é…ç½®æ–‡ä»¶å­˜åœ¨")
    
    # 4. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
    if not os.path.exists("venv"):
        issues.append("âš ï¸  è™šæ‹Ÿç¯å¢ƒä¸å­˜åœ¨")
    else:
        print("âœ… è™šæ‹Ÿç¯å¢ƒå­˜åœ¨")
    
    print()
    print("=" * 60)
    
    if issues:
        print("âš ï¸  å‘ç°ä»¥ä¸‹é—®é¢˜ï¼š")
        for issue in issues:
            print(f"  {issue}")
        print()
        print("å»ºè®®è¿è¡Œ: python scripts/cleanup.py")
    else:
        print("âœ… ç³»ç»ŸçŠ¶æ€å¥åº·")
    
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(health_check())
```

è¿è¡Œå¥åº·æ£€æŸ¥ï¼š

```bash
python scripts/health_check.py
```

---

## ğŸ†˜ ç´§æ€¥æ¢å¤

å¦‚æœç³»ç»Ÿå‡ºç°ä¸¥é‡é—®é¢˜ï¼š

1. **ç«‹å³åœæ­¢æ‰€æœ‰æ“ä½œ**
2. **å¤‡ä»½å½“å‰çŠ¶æ€**ï¼ˆå³ä½¿å·²æŸåï¼‰
3. **ä»æœ€è¿‘çš„å¤‡ä»½æ¢å¤**
4. **è¿è¡Œå¥åº·æ£€æŸ¥**
5. **é‡æ–°åŒæ­¥é£ä¹¦æ•°æ®**ï¼ˆå¦‚æœå¤‡ä»½ä¸å®Œæ•´ï¼‰

---

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°æ— æ³•è§£å†³çš„é—®é¢˜ï¼š

1. æ£€æŸ¥æ—¥å¿—è¾“å‡º
2. è¿è¡Œå¥åº·æ£€æŸ¥è„šæœ¬
3. æŸ¥çœ‹æµ‹è¯•æŠ¥å‘Š
4. å‚è€ƒ `scripts/README.md`

æ›´å¤šä¿¡æ¯è¯·å‚è€ƒä¸» README.mdã€‚
